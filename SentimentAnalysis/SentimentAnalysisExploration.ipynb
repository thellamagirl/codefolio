{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d827ce17",
   "metadata": {},
   "source": [
    "# Unveiling Sentiments: Exploring Customer Reviews using Logistic Regression, Random Forest, and CNN-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960d6ec5",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cf56b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "from pylab import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 6, 5\n",
    "%matplotlib inline\n",
    "sns.set_theme(style='white')\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Plot function\n",
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82392fc5",
   "metadata": {},
   "source": [
    "### Combine Review Texts into Single CSV for Sentiment Analysis\n",
    "The code combines review texts from three separate text files (Amazon reviews, IMDB movie reviews, and Yelp reviews) into a single CSV file. This consolidated dataset is then used for sentiment analysis in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e63f9713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file addresses\n",
    "address1 = \"Data/amazon_cells_labelled.txt\"\n",
    "address2 = \"Data/imdb_labelled.txt\"\n",
    "address3 = \"Data/yelp_labelled.txt\"\n",
    "\n",
    "# Read data from files into dataframes\n",
    "df1 = pd.read_csv(address1, delimiter='\\t', header=None)\n",
    "df2 = pd.read_csv(address2, delimiter='\\t', header=None)\n",
    "df3 = pd.read_csv(address3, delimiter='\\t', header=None)\n",
    "\n",
    "# Concatenate the dataframes vertically\n",
    "df = pd.concat([df1, df2, df3], axis=0)\n",
    "\n",
    "# Set column names\n",
    "df.columns = [\"Review\", \"Sentiment\"]\n",
    "\n",
    "# Uncomment the line below if you want to save the combined data to a CSV file\n",
    "#df.to_csv('combined_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ce9a68",
   "metadata": {},
   "source": [
    "### Data Reading with Pandas\n",
    "The data file was read into a Pandas dataframe using the Pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8f53ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment\n",
       "0  So there is no way for me to plug it in here i...          0\n",
       "1                        Good case, Excellent value.          1\n",
       "2                             Great for the jawbone.          1\n",
       "3  Tied to charger for conversations lasting more...          0\n",
       "4                                  The mic is great.          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in dataframe\n",
    "df = pd.read_csv('combined_data.csv')\n",
    "\n",
    "# Display the first few rows of the combined dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0921a3",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74c44ed",
   "metadata": {},
   "source": [
    "### Remove Duplicate Values in Review Column\n",
    "All rows consisting of duplicate values were dropped from the dataframe. Using the length of the dataframe as a reference, performing this step removed 17 rows that contained duplicate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "106e6f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the dataframe: 2731\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Reset the index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Get the length of the dataframe\n",
    "df_length = len(df)\n",
    "\n",
    "print(\"Length of the dataframe:\", df_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de3ae5c",
   "metadata": {},
   "source": [
    "### Clean and Tokenize Reviews\n",
    "Text preprocessing is a crucial step in natural language processing (NLP). In this project, a custom function was created using well-known tools from the NLTK library to perform the necessary text processing.\n",
    "\n",
    "The function applies a series of transformations to the reviews:\n",
    "\n",
    "- Conversion to lowercase: All letters in the reviews are converted to lowercase for consistency.\n",
    "- Tokenization: The reviews are tokenized, separating them into individual word tokens.\n",
    "- Lemmatization: The tokens are lemmatized to reduce words to their base form, improving analysis accuracy.\n",
    "- Stopword removal: Commonly occurring stop words are removed to eliminate noise in the text.\n",
    "- Alphabetic character retention: Only tokens containing alphabetic characters are retained, filtering out numbers and special characters.\n",
    "- Unique token filtering: From the cleaned tokens, only unique tokens greater than two letters in length are kept in each review.\n",
    "\n",
    "After the cleaning and tokenization process, the number of tokens in each review is counted. Any reviews with zero tokens are dropped from the dataset as they do not contain meaningful information for analysis.\n",
    "\n",
    "The cleaned reviews are then stored in two new columns in the dataframe. One column contains the tokenized reviews, where each review is represented as a list of individual tokens. The other column contains the cleaned reviews as strings, where the tokens are joined into a cleaned review text.\n",
    "\n",
    "Additionally, the code counts the vocabulary size by analyzing the tokenized review column. This information will be used when building the CNN-LSTM neural network.\n",
    "\n",
    "By applying these cleaning and tokenization steps, as well as filtering out reviews with zero tokens, the reviews are transformed into a structured and standardized format, ready for further analysis in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "559fb44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>tokenized_review</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>{plug, converter, way, unless}</td>\n",
       "      <td>plug converter way unless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "      <td>{good, case, value, excellent}</td>\n",
       "      <td>good case value excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "      <td>{great, jawbone}</td>\n",
       "      <td>great jawbone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "      <td>{conversation, problem, tied, charger, lasting}</td>\n",
       "      <td>conversation problem tied charger lasting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "      <td>{mic, great}</td>\n",
       "      <td>mic great</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment  \\\n",
       "0  So there is no way for me to plug it in here i...          0   \n",
       "1                        Good case, Excellent value.          1   \n",
       "2                             Great for the jawbone.          1   \n",
       "3  Tied to charger for conversations lasting more...          0   \n",
       "4                                  The mic is great.          1   \n",
       "\n",
       "                                  tokenized_review  \\\n",
       "0                   {plug, converter, way, unless}   \n",
       "1                   {good, case, value, excellent}   \n",
       "2                                 {great, jawbone}   \n",
       "3  {conversation, problem, tied, charger, lasting}   \n",
       "4                                     {mic, great}   \n",
       "\n",
       "                              cleaned_review  \n",
       "0                  plug converter way unless  \n",
       "1                  good case value excellent  \n",
       "2                              great jawbone  \n",
       "3  conversation problem tied charger lasting  \n",
       "4                                  mic great  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to clean reviews and drop rows with 0 tokens\n",
    "def clean_reviews(text):\n",
    "    # Tokenize the text and convert to lowercase\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Check if the number of tokens is 0\n",
    "    if len(tokens) == 0:\n",
    "        return pd.Series([[], ''], index=['tokenized_review', 'cleaned_review'])\n",
    "    \n",
    "    # Get the list of stopwords\n",
    "    stop_words = nltk.corpus.stopwords.words('english')\n",
    "    \n",
    "    # Lemmatize the tokens\n",
    "    lemmas = [wordnet_lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Filter out non-alphabetic words and stopwords\n",
    "    clean_text = [word for word in lemmas if word.isalpha() and not word in stop_words]\n",
    "    \n",
    "    # Get unique tokens with length greater than 1\n",
    "    unique_tokens = set([word for word in clean_text if len(word) > 2])\n",
    "    \n",
    "    # Join the unique tokens into a cleaned review string\n",
    "    cleaned_text = ' '.join(unique_tokens)\n",
    "    \n",
    "    return pd.Series([unique_tokens, cleaned_text], index=['tokenized_review', 'cleaned_review'])\n",
    "\n",
    "# Apply the clean_reviews function to the 'Review' column, creating new columns 'tokenized_review' and 'cleaned_review'\n",
    "df[['tokenized_review', 'cleaned_review']] = df['Review'].apply(clean_reviews)\n",
    "\n",
    "# Drop rows with 0 tokens\n",
    "df = df[df['tokenized_review'].apply(len) > 0]\n",
    "\n",
    "# Calculate the vocab_size\n",
    "vocabulary = set()\n",
    "for tokens in df['tokenized_review']:\n",
    "    vocabulary.update(tokens)\n",
    "vocab_size = len(vocabulary)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03c9091",
   "metadata": {},
   "source": [
    "## Word Embedding\n",
    "In this project, it was crucial to convert the words in each review into a numerical representation. This transformation process is known as word embedding, where words or text are mapped into a vector space to capture semantic relationships and contextual information. By representing words numerically, machine learning algorithms that require numerical inputs can be effectively utilized.\n",
    "\n",
    "To enhance the semantic relationships and patterns present in the review text, a pre-trained Word2Vec model was employed. Word embeddings encode semantic meanings and similarities between words, enabling the model to learn from the underlying patterns and relationships within the text data.\n",
    "\n",
    "The application of word embedding in this project facilitated the conversion of reviews into a numerical representation. This enabled the use of numerical-based models, particularly for sentiment analysis. By transforming the reviews into a numerical format, the models gained the ability to understand and analyze the text data, uncovering patterns and making predictions based on the learned relationships between words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348c31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained FastText model with the correct encoding\n",
    "word2vec_model = KeyedVectors.load_word2vec_format('wiki.en.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338610fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store the review embeddings\n",
    "review_embeddings = []\n",
    "\n",
    "# Iterate over tokenized reviews\n",
    "for review_tokens in df['tokenized_review']:\n",
    "    # Initialize an empty review embedding\n",
    "    review_embedding = np.zeros(word2vec_model.vector_size)\n",
    "    \n",
    "    # Iterate over tokens in the review\n",
    "    for token in review_tokens:\n",
    "        # Check if the token exists in the FastText vocabulary\n",
    "        if token in word2vec_model:\n",
    "            # Add the token's embedding to the review embedding\n",
    "            review_embedding += word2vec_model[token]\n",
    "    \n",
    "    # Append the review embedding to the list\n",
    "    review_embeddings.append(review_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e6139c",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "In this section, various analyses were conducted to gain insights into the dataset. The following steps were performed:\n",
    "\n",
    "1. Dataset Information: The structure and summary of the dataset were examined using `df.info()`. This provided details such as the number of rows, columns, and column data types.\n",
    "\n",
    "2. Sentiment Distribution: The distribution of sentiments was visualized using a countplot on the 'Sentiment' column. `df['Sentiment'].value_counts()` was used to obtain the count of each sentiment class, enabling an understanding of the sentiment balance in the dataset.\n",
    "\n",
    "3. Word Frequency Analysis: A word cloud was generated to visualize the frequency of words in the dataset. This analysis provided a visual representation of the most common words or phrases present in the reviews.\n",
    "\n",
    "4. Review Length: The number of words in each review was calculated, providing insights into the length and complexity of the reviews. A histogram of word lengths was created to visualize the distribution and identify any patterns.\n",
    "\n",
    "These exploratory analyses shed light on the dataset, allowing for a better understanding of the sentiment distribution, prominent words or phrases, and the length characteristics of the reviews. This information serves as a foundation for further analysis and modeling in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f09a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display information about the dataframe\n",
    "df.info();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21265a2a",
   "metadata": {},
   "source": [
    "### Sentiment Distribution\n",
    "A count plot was created for the Sentiment variable. These count plots show the distribution by class and help visualize the class imbalance that will need to be handled during the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf43e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Sentiment', data=df, palette='hls')\n",
    "plt.title('Distribution by Sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f18d05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a796d5",
   "metadata": {},
   "source": [
    "### Word Frequency & Word Cloud Visualization\n",
    "To gain insights into the most frequent words in the review dataset, a word cloud visualization was created. The word cloud provides a visual representation of the most commonly occurring words in the dataset.\n",
    "\n",
    "The process began by combining all the cleaned review texts into a single string, representing the entire corpus of reviews. This consolidated text was then used to generate a word cloud using the WordCloud object from the WordCloud library. The word cloud was configured to have a width of 800 pixels, height of 400 pixels, and display a maximum of 200 words. The background color was set to white for clarity.\n",
    "\n",
    "The resulting word cloud was displayed using the matplotlib library, which allowed for the visualization of the word cloud image. The word cloud image presents the words in varying sizes based on their frequency, with more frequent words appearing larger and more prominent.\n",
    "\n",
    "The word cloud visualization provides a quick overview of the most frequent words in the dataset, highlighting the prominent themes or topics that emerge from the reviews. It serves as a useful tool for understanding the dominant sentiments or subjects expressed in the reviews, aiding in the exploration and analysis of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e4d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the cleaned review texts into a single string\n",
    "combined_text = ' '.join(df['cleaned_review'])\n",
    "\n",
    "# Create a WordCloud object\n",
    "wordcloud = WordCloud(width=800, height=400, max_words=200, background_color='white').generate(combined_text)\n",
    "\n",
    "# Display the word cloud using matplotlib\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99206b5",
   "metadata": {},
   "source": [
    "### Calculate Number of Words per Review\n",
    "Although not directly required for sentiment analysis, knowing the number of words in each review is essential for certain tasks like setting a maximum length in neural networks. Additionally, exploring this aspect provides insights into how the review length influences sentiment analysis.\n",
    "\n",
    "To calculate the number of words in each review, the dataframe's built-in apply function was utilized in combination with a custom function. This function split each review by spaces, effectively separating individual words. The length of each split word was then calculated, and a new column containing the word count for each review was added to the dataframe.\n",
    "\n",
    "By incorporating this word count column into the dataframe, we gain valuable information about the length of each review, enabling a deeper understanding of how review length might impact sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35334264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns number of tokens in set\n",
    "def token_count(token_set):\n",
    "    # Return length of token set\n",
    "    return len(token_set)\n",
    "\n",
    "# Create num_tokens feature in df\n",
    "df['num_tokens'] = df['tokenized_review'].apply(token_count)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb04814",
   "metadata": {},
   "source": [
    "### Exploring Review Lengths\n",
    "In this section, various statistics were calculated to gain insights into the lengths of the reviews. The following metrics were calculated:\n",
    "\n",
    "- Longest Review: The length of the longest review, representing the maximum number of tokens in a single review.\n",
    "- Shortest Review: The length of the shortest review, indicating the minimum number of tokens in a single review.\n",
    "- Average Review Length: The average number of tokens across all reviews, providing a measure of the typical length of a review.\n",
    "- Standard Deviation: The standard deviation of the review lengths, indicating the variation or spread of review lengths from the average.\n",
    "- Median Review Length: The median length of the reviews, representing the middle value when the review lengths are sorted.\n",
    "\n",
    "By computing these statistics, we obtain a comprehensive understanding of the distribution and characteristics of the review lengths in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d5f89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate review lengths\n",
    "review_lengths = df['num_tokens']\n",
    "\n",
    "# Calculate statistics\n",
    "longest_review = max(review_lengths)\n",
    "shortest_review = min(review_lengths)\n",
    "average_length = round(np.mean(review_lengths))\n",
    "standard_deviation = round(np.std(review_lengths))\n",
    "median_length = round(np.median(review_lengths))\n",
    "\n",
    "# Print the results\n",
    "print(f\"The longest review is {longest_review} tokens.\")\n",
    "print(f\"The shortest review is {shortest_review} tokens.\")\n",
    "print(f\"The average review length is {average_length} tokens.\")\n",
    "print(f\"The standard deviation of the token count is {standard_deviation} tokens.\")\n",
    "print(f\"The median review length is {median_length} tokens.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f5d5d4",
   "metadata": {},
   "source": [
    "### Visualizing Review Length Distribution\n",
    "A a count plot was generated to visualize the distribution of the number of words per review. The plot is displayed using the Seaborn library, with a figure size of 14x6 and a white background style.\n",
    "\n",
    "The x-axis of the plot represents the number of words per review, while the y-axis represents the count of reviews falling into each length category. The color palette 'hls' was used to differentiate the bars in the plot.\n",
    "\n",
    "The plot provides an overview of the distribution of review lengths, allowing for a better understanding of the range and prevalence of different review lengths within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdce330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size and style\n",
    "sns.set(rc={'figure.figsize':(14, 6)}, style='white')\n",
    "\n",
    "# Create the count plot\n",
    "sns.countplot(x=df['num_tokens'], palette='hls')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('Number of Words per Review')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Review Length Distribution')\n",
    "\n",
    "# Display the plot\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260ed5b7",
   "metadata": {},
   "source": [
    "### Split the Data\n",
    "To prepare the data for training and testing, it was split into training and testing sets. The review embeddings were used as the input feature (X), while the labeled Sentiment variable served as the target variable (y). The data was split in an 80:20 ratio, with 80% allocated for training and 20% for testing.\n",
    "\n",
    "The split was performed with the consideration of maintaining balanced proportions of each sentiment label in both the training and testing sets. This approach, known as stratified splitting, ensures that the distribution of sentiment labels is similar in both sets, avoiding potential bias or skewed performance evaluation.\n",
    "\n",
    "Additionally, the data was shuffled during the splitting process to prevent any inherent order or pattern from affecting the distribution of the sentiment labels across the sets.\n",
    "\n",
    "By splitting the data into training and testing sets, we create distinct subsets that can be used to train the model on a representative portion of the data and evaluate its performance on unseen data. This allows for a more robust assessment of the model's accuracy and generalization capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c361d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the target variable\n",
    "y = df['Sentiment']\n",
    "X = review_embeddings\n",
    "\n",
    "# Create Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=42,\n",
    "                                                   stratify=y,\n",
    "                                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b652d9e",
   "metadata": {},
   "source": [
    "## Sentiment Analysis using Logistic Regression with Cross-Validation and Performance Evaluation\n",
    "\n",
    "In this project, logistic regression with cross-validation was employed to build a sentiment analysis model. The logistic regression model utilized the `LogisticRegressionCV` method from the sklearn library, which incorporates cross-validation for more reliable performance evaluation. In addition to that, the C and l1_ratios parameters are tuned using a stratified 5-fold cross-validation, optimum selection based upon accuracy scores (Pedregosa et al., 2011). \n",
    "\n",
    "The logistic regression model was trained on the training data and then used to predict labels for the test data. A threshold of 0.5 was applied to convert the continuous predicted values into binary predictions. The accuracy, precision, recall, and F1-score were calculated using these binary predictions against the true labels of the test data.\n",
    "\n",
    "The accuracy score reflects the proportion of correctly classified instances among all instances in the test data. The precision score measures the model's ability to correctly identify positive sentiment, while the recall score captures the model's ability to identify all positive sentiment instances. The F1-score provides a balanced measure of the model's precision and recall.\n",
    "\n",
    "Using the logistic regression model trained with cross-validation, the performance of the model on the test data was evaluated. The accuracy score on the test data was calculated to assess the overall correctness of the model's predictions. Additionally, precision, recall, and F1-score were determined to evaluate the model's classification performance for sentiment analysis.\n",
    "\n",
    "The logistic regression model achieved the following performance metrics on the test data:\n",
    "- Accuracy score on test data: 0.7967\n",
    "- Precision score on test data: 0.7887\n",
    "- Recall score on test data: 0.8145\n",
    "- F1-score on test data: 0.8014\n",
    "\n",
    "Furthermore, the log loss and AUC-ROC metrics were calculated to provide additional insights into the model's performance. The log loss measures the model's predictive uncertainty, with lower values indicating better performance. The AUC-ROC (Area Under the Receiver Operating Characteristic) score quantifies the model's ability to distinguish between positive and negative sentiment, with higher values indicating better discriminatory power.\n",
    "\n",
    "The logistic regression model achieved a log loss of 7.3276 and an AUC-ROC of 0.7966 on the test data.\n",
    "\n",
    "By employing logistic regression with cross-validation, this project establishes a reliable classification approach for sentiment analysis, allowing for accurate predictions and comprehensive evaluation of the model's performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9c5dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a logistic regression model with cross-validation\n",
    "log_reg = LogisticRegressionCV(random_state=42, n_jobs=-1, solver='liblinear', cv=5)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Apply threshold to convert continuous predicted values to binary predictions\n",
    "threshold = 0.5\n",
    "y_pred_binary = [1 if val > threshold else 0 for val in y_pred]\n",
    "\n",
    "# Calculate the evaluation metrics on the test data\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "precision = precision_score(y_test, y_pred_binary)\n",
    "recall = recall_score(y_test, y_pred_binary)\n",
    "f1 = f1_score(y_test, y_pred_binary)\n",
    "log_loss_value = log_loss(y_test, y_pred_binary)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_binary)\n",
    "\n",
    "# Print the evaluation metrics on the test data\n",
    "print('Accuracy score on test data: {:.4f}'.format(accuracy))\n",
    "print('Precision score on test data: {:.4f}'.format(precision))\n",
    "print('Recall score on test data: {:.4f}'.format(recall))\n",
    "print('F1-score on test data: {:.4f}'.format(f1))\n",
    "print('Log loss on test data: {:.4f}'.format(log_loss_value))\n",
    "print('AUC-ROC on test data: {:.4f}'.format(roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf402a",
   "metadata": {},
   "source": [
    "### Logistic Regression Classification Report\n",
    "\n",
    "To assess the true performance of a model, it is essential to compare the predicted labels against the true labels. This evaluation provides a reliable measure of the model's accuracy when making predictions on new, unseen data. The F1-score is described as \"...the harmonic mean of the model’s precision and recall\" (Wood, 2019) is a useful metric to evaluate the model's overall performance.\n",
    "\n",
    "The F1-score provides an indication of the model's ability to achieve a balance between minimizing false positives (precision) and false negatives (recall).\n",
    "\n",
    "The classification report table below showcases the F1-scores for each sentiment label:\n",
    "\n",
    "| Sentiment Label | F1-Score | Number of Samples |\n",
    "|-----------------|----------|------------------|\n",
    "| Negative (0)    | 79%      | 271              |\n",
    "| Positive (1)    | 80%      | 275              |\n",
    "\n",
    "In the classification report, we observe that the logistic regression model achieved an F1-score of 79% for the negative sentiment label (label 0), indicating a good balance between precision and recall. The model correctly identified negative sentiment in 80% of the samples belonging to this category. Additionally, for the positive sentiment label (label 1), the model achieved an F1-score of 80%, demonstrating a similar balance between precision and recall in identifying positive sentiment.\n",
    "\n",
    "These results provide insights into the model's performance for each sentiment label, allowing for a more comprehensive understanding of its effectiveness in sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b25f22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8239b2ec",
   "metadata": {},
   "source": [
    "### Logistic Regression Confusion Matrix Heatmap\n",
    "To visually analyze the performance of the logistic regression model, a confusion matrix was created using sklearn's `confusion_matrix` function and seaborn. The confusion matrix provides a comprehensive representation of the actual versus predicted counts for each label.\n",
    "\n",
    "In the generated confusion matrix heatmap, the diagonal elements represent the true positives for each class. For negative sentiment (label 0), there were 211 correct predictions, while for positive sentiment (label 1), there were 224 correct predictions. The off-diagonal elements correspond to the false positives and false negatives for both classes, representing the misclassifications made by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ed33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "lr_confusion_matrix = confusion_matrix(y_test, y_pred_binary)\n",
    "\n",
    "class_names = ['0', '1']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Create the heatmap\n",
    "sns.heatmap(pd.DataFrame(lr_confusion_matrix), annot=True, cmap='viridis', fmt='g', robust=True, center=0,\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "ax.xaxis.set_label_position('top')\n",
    "plt.tight_layout()\n",
    "plt.title('Logistic Regression Confusion Matrix', y=1.1)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15184e80",
   "metadata": {},
   "source": [
    "## Sentiment Analysis using Random Forest Regression with Cross-Validation and Performance Evaluation\n",
    "In this section, sentiment analysis was performed using Random Forest Regression with cross-validation. Random Forest was chosen as the prediction method for this analysis due to its ability to handle both linear and non-linear relationships and its ensemble nature.\n",
    "\n",
    "Random Forest is an ensemble model that utilizes multiple decision trees to arrive at the final predicted outcome (Chakure, 2020). It combines the predictions of multiple decision trees by aggregating them, typically using the average of the predictions. This ensemble approach allows Random Forest to capture complex patterns and relationships in the data, making it a suitable choice for sentiment analysis tasks.\n",
    "\n",
    "The Random Forest model was trained and evaluated using the same dataset as the logistic regression. It achieved the following performance metrics on the test data:\n",
    "\n",
    "- Accuracy score on test data: 0.7509\n",
    "- Precision score on test data: 0.7422\n",
    "- Recall score on test data: 0.7745\n",
    "- F1-score on test data: 0.7580\n",
    "\n",
    "In addition to these metrics, log loss and AUC-ROC were calculated to provide further insights into the model's performance. Log loss measures the predictive uncertainty of the model, with lower values indicating better performance. AUC-ROC (Area Under the Receiver Operating Characteristic) score quantifies the model's ability to distinguish between positive and negative sentiment, with higher values indicating better discriminatory power.\n",
    "\n",
    "The Random Forest model achieved a log loss of 8.9779 and an AUC-ROC of 0.7507 on the test data.\n",
    "\n",
    "By utilizing Random Forest regression with hyperparameter tuning, this project establishes an effective approach for sentiment analysis. The model demonstrates its ability to make accurate predictions and provides a comprehensive evaluation of its performance on the test data.\n",
    "\n",
    "The model was trained using the GridSearchCV technique to find the best combination of hyperparameters. The optimal hyperparameters obtained were as follows:\n",
    "\n",
    "- max_depth: 9\n",
    "- max_features: 0.5\n",
    "- min_samples_leaf: 2\n",
    "- n_estimators: 300\n",
    "\n",
    "The best model, obtained with these hyperparameters, was used to predict probabilities on the test data. A threshold of 0.5 was applied to convert the continuous predicted values to binary predictions. The evaluation metrics, including accuracy, precision, recall, and F1-score, were calculated based on these binary predictions. Additionally, log loss and AUC-ROC were computed to provide a more comprehensive assessment of the model's performance.\n",
    "\n",
    "The test set performance metrics of the Random Forest model further contribute to the overall comparison and evaluation of the different models employed in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c13467",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instantiate RF \n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define hyperparams\n",
    "params_rf = {\n",
    "             'n_estimators':[400, 600, 800],\n",
    "             'max_depth':[5, 7, 9],\n",
    "             'min_samples_leaf':[1, 2, 3],\n",
    "             'max_features':['sqrt', 0.5, 0.9]\n",
    "            }\n",
    "\n",
    "# Instantiate grid search object 'grid_rf'\n",
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                       param_grid=params_rf,\n",
    "                       cv=5,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)\n",
    "# Fit 'grid_rf' to training data\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "# Extract best hyperparams from 'grid_rf'\n",
    "best_hyperparams = grid_rf.best_params_\n",
    "print('Best hyperparameters:\\n', best_hyperparams)\n",
    "\n",
    "# Extract best model from 'grid_rf'\n",
    "best_model = grid_rf.best_estimator_\n",
    "\n",
    "# Predict probabilities on test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Apply threshold to convert continuous predicted values to binary predictions\n",
    "threshold = 0.5\n",
    "y_pred_binary = [1 if val > threshold else 0 for val in y_pred]\n",
    "\n",
    "# Calculate the evaluation metrics on the test data\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "precision = precision_score(y_test, y_pred_binary)\n",
    "recall = recall_score(y_test, y_pred_binary)\n",
    "f1 = f1_score(y_test, y_pred_binary)\n",
    "logloss = log_loss(y_test, y_pred_binary)\n",
    "auc_roc = roc_auc_score(y_test, y_pred_binary)\n",
    "\n",
    "# Evaluate metrics on the test data\n",
    "mse_test = MSE(y_test, y_pred)\n",
    "rmse_test = mse_test ** (1 / 2)\n",
    "print()\n",
    "print('Test set RMSE: {:.4f}'.format(rmse_test))\n",
    "print('Test set MSE: {:.4f}'.format(mse_test))\n",
    "print('Test set accuracy: {:.4f}'.format(accuracy))\n",
    "print('Test set precision: {:.4f}'.format(precision))\n",
    "print('Test set recall: {:.4f}'.format(recall))\n",
    "print('Test set F1-score: {:.4f}'.format(f1))\n",
    "print('Test set log loss: {:.4f}'.format(logloss))\n",
    "print('Test set AUC-ROC: {:.4f}'.format(auc_roc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675defe9",
   "metadata": {},
   "source": [
    "### Random Forest Regression Classification Report\n",
    "To assess the true performance of the Random Forest model in sentiment analysis, we compare the predicted labels against the true labels on the test data. The F1-score, which is the harmonic mean of precision and recall, provides a reliable metric to evaluate the model's overall performance (Wood, 2019).\n",
    "\n",
    "The classification report below presents the F1-scores for each sentiment label:\n",
    "\n",
    "| Sentiment Label | F1-Score | Number of Samples |\n",
    "|-----------------|----------|------------------|\n",
    "| Negative (0)    | 74%      | 271              |\n",
    "| Positive (1)    | 76%      | 275              |\n",
    "\n",
    "The Random Forest model achieved an F1-score of 74% for the negative sentiment label (label 0), indicating a reasonable balance between precision and recall. The model correctly identified negative sentiment in 74% of the samples belonging to this category. For the positive sentiment label (label 1), the model achieved an F1-score of 76%, demonstrating a similar balance between precision and recall in identifying positive sentiment.\n",
    "\n",
    "The classification report further breaks down precision, recall, and F1-score for each sentiment label. It shows that the model's precision for the negative sentiment label is 76% and recall is 73%, while for the positive sentiment label, the precision is 74% and recall is 77%. These metrics highlight the model's ability to make accurate predictions for both negative and positive sentiment.\n",
    "\n",
    "Overall, the Random Forest model demonstrates a reasonable performance in sentiment analysis, achieving a balanced F1-score for both negative and positive sentiment labels. These results provide valuable insights into the model's effectiveness in accurately classifying sentiment and contribute to the comprehensive evaluation of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aecbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22062d7",
   "metadata": {},
   "source": [
    "### Random Forest Confusion Matrix Heatmap\n",
    "To visually analyze the performance of the Random Forest model in sentiment analysis, a confusion matrix heatmap was created using the `confusion_matrix` function from sklearn and visualized using seaborn. The confusion matrix provides a comprehensive representation of the actual versus predicted counts for each sentiment label.\n",
    "\n",
    "In the generated confusion matrix heatmap, the diagonal elements represent the true positives for each class. For the negative sentiment (label 0), there were 197 correct predictions, indicating that the model accurately classified 197 samples as negative sentiment. Similarly, for the positive sentiment (label 1), there were 213 correct predictions, signifying the accurate classification of 213 samples as positive sentiment.\n",
    "\n",
    "The off-diagonal elements of the confusion matrix correspond to the false positives and false negatives for both sentiment labels. In this case, there were 62 false positives, indicating the instances where the model incorrectly predicted a positive sentiment when the true sentiment was negative. Additionally, there were 74 false negatives, representing the instances where the model incorrectly predicted a negative sentiment when the true sentiment was positive.\n",
    "\n",
    "By examining the confusion matrix heatmap, we can gain insights into the model's performance in terms of misclassifications and correct predictions for each sentiment label. This visualization allows for a more comprehensive understanding of the model's effectiveness in sentiment analysis and highlights areas where improvements can be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece0ad35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "rf_confusion_matrix = confusion_matrix(y_test, y_pred_binary)\n",
    "\n",
    "class_names = ['0', '1']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Create the heatmap\n",
    "sns.heatmap(pd.DataFrame(rf_confusion_matrix), annot=True, cmap='viridis', fmt='g', robust=True, center=0,\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "ax.xaxis.set_label_position('top')\n",
    "plt.tight_layout()\n",
    "plt.title('Random Forest Confusion Matrix', y=1.1)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da589535",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with CNN-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a082499",
   "metadata": {},
   "source": [
    "### Preprocessing Text Data with TensorFlow\n",
    "\n",
    "TensorFlow was selected as the platform for the neural network due to its comprehensive set of tools and libraries that facilitate both preprocessing tasks and model building capabilities (TensorFlow, n.d.).\n",
    "\n",
    "To prepare the reviews for input into the CNN-LSTM neural network, a series of preprocessing steps were performed. First, the cleaned reviews were tokenized, which involved splitting the text into individual words or tokens. This tokenization step allows the network to treat each word as a separate unit.\n",
    "\n",
    "Next, the tokenized reviews were converted into sequences of numbers. Each unique word in the vocabulary was assigned a unique numerical index, and the reviews were transformed into sequences of these indices. This numerical representation enables the neural network to process and analyze the text data.\n",
    "\n",
    "To ensure that all reviews have the same length, padding was applied. The reviews were padded or truncated to a maximum sequence length of 17, which means that each review was represented by a fixed-length sequence of 17 numbers. This padding process guarantees uniform input dimensions for the neural network.\n",
    "\n",
    "The choice of a maximum sequence length of 17 was determined based on the distribution of review lengths. By setting the length to be 1 standard deviation above the median review length, the aim was to preserve the majority of sentiment information contained within the reviews. This approach helps to handle the varying lengths of reviews and ensures that important sentiment-related information is retained.\n",
    "\n",
    "By performing these preprocessing steps, the reviews were transformed into a suitable format for training the CNN-LSTM neural network using TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301de163",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 17 # med + 1 std\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(df['cleaned_review'])\n",
    "sequences = tokenizer.texts_to_sequences(df['cleaned_review'])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, truncating='post', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9e1f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4151d78",
   "metadata": {},
   "source": [
    "### Splitting the Data for CNN-LSTM\n",
    "\n",
    "The dataset was partitioned into training and testing sets to facilitate the training and evaluation of the CNN-LSTM model. The splitting process involved allocating 80% of the data to the training set and the remaining 20% to the testing set. \n",
    "\n",
    "For the input features (X), the padded sequences obtained during the preprocessing step were utilized. These sequences represent the numerical representations of the reviews after tokenization and padding. The target variable, denoting the sentiment of each review, was assigned to 'Sentiment' (y).\n",
    "\n",
    "To ensure a representative distribution of sentiment labels in both the training and testing sets, stratification was applied. This stratification technique helps to maintain similar proportions of each sentiment label in both subsets, preventing any bias that may arise due to imbalanced data. Additionally, the data was shuffled to randomize the order of the samples during the splitting process.\n",
    "\n",
    "By splitting the data into distinct training and testing sets, we can effectively train the CNN-LSTM model on the training data and evaluate its performance on unseen data from the testing set. This separation enables us to assess the model's ability to generalize to new reviews and make accurate sentiment predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1ea52c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assign the target variable\n",
    "y = df['Sentiment']\n",
    "X = padded_sequences\n",
    "\n",
    "\n",
    "# Create Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=42,\n",
    "                                                   stratify=y,\n",
    "                                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30679eed",
   "metadata": {},
   "source": [
    "### Building the CNN-LSTM Model\n",
    "\n",
    "The CNN-LSTM model was constructed using a Sequential model in TensorFlow, integrating both convolutional and recurrent neural network layers. This model leverages the power of deep learning to capture complex patterns and relationships within the review data.\n",
    "\n",
    "To enhance the performance and take advantage of pre-trained word embeddings, an embedding matrix was created using the Word2Vec model. This matrix was used as input to the embedding layer of the CNN-LSTM model. By incorporating the pre-trained embeddings, the model can benefit from the rich semantic information captured by the Word2Vec model, leading to a more effective representation of the textual data.\n",
    "\n",
    "The model architecture starts with an embedding layer, which sets the word embeddings for the model based on the vocabulary size and the maximum review length. The embedding layer converts each word in the review into a dense vector representation. \n",
    "\n",
    "Following the embedding layer, a series of layers are added to capture and extract features from the text data. This includes a one-dimensional convolutional layer, batch normalization layer, and max pooling layer. These layers help to detect local patterns and important features in the text data.\n",
    "\n",
    "Next, a dropout layer is added to reduce overfitting, followed by two LSTM layers, each accompanied by a batch normalization layer. The LSTM layers enable the model to capture long-term dependencies and sequential information in the reviews.\n",
    "\n",
    "Afterwards, a dense layer with batch normalization is added, which further processes the extracted features. Finally, a dense output layer with a sigmoid activation function is included to produce binary predictions for sentiment analysis.\n",
    "\n",
    "The model is compiled using the Adam optimizer, a popular stochastic gradient descent optimizer known for its efficiency when dealing with a large number of parameters (Abadi et al., 2015). The learning rate for the optimizer is set based on the optimal value obtained during hyperparameter tuning.\n",
    "\n",
    "Binary crossentropy loss function is utilized as it is well-suited for binary classification tasks, such as sentiment analysis (Introduction to Deep Learning with Keras). This loss function calculates the difference between the predicted and actual labels, optimizing the model's ability to accurately classify sentiment.\n",
    "\n",
    "To optimize the model's performance and find the best set of hyperparameters, a hyperparameter search was performed using Keras Tuner. The search involved tuning parameters such as the number of convolutional filters, activation functions, LSTM units, dropout rates, dense layer size, and the learning rate for the optimizer. The search was conducted for a maximum of 10 trials, aiming to minimize the validation loss.\n",
    "\n",
    "After the hyperparameter search, the best hyperparameters were obtained, revealing the optimal configuration for the CNN-LSTM model. These hyperparameters include the number of convolutional filters, activation functions, LSTM units, dropout rate, dense layer size, and the learning rate for the optimizer.\n",
    "\n",
    "The resulting model achieved a validation loss of 0.4289 during the hyperparameter search, indicating its ability to effectively learn and generalize patterns from the training data. The optimal hyperparameters serve as a guide for configuring the model to achieve improved performance in sentiment analysis.\n",
    "\n",
    "By utilizing the CNN-LSTM model architecture and optimizing its hyperparameters, the aim is to develop a robust and accurate sentiment analysis model capable of capturing intricate patterns in textual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4bf343",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_sequence_length = 17 # 1 std + median\n",
    "vocab_size = len(tokenizer.word_index) + 1 # Add 1 for the unknown token\n",
    "embedding_dim = word2vec_model.vector_size\n",
    "\n",
    "address = \"CNN-LSTM-Model\"\n",
    "\n",
    "\n",
    "# Establish callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
    "modelCheckpoint = ModelCheckpoint('best_model.hdf5', save_best_only = True)\n",
    "\n",
    "\n",
    "def create_embedding_matrix(word2vec_model, tokenizer):\n",
    "    embedding_dim = word2vec_model.vector_size\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if word in word2vec_model:\n",
    "            embedding_matrix[i] = word2vec_model[word]\n",
    "    return embedding_matrix\n",
    "\n",
    "embedding_matrix = create_embedding_matrix(word2vec_model, tokenizer)\n",
    "\n",
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=embedding_dim,\n",
    "            input_length=max_sequence_length,\n",
    "            trainable=False,\n",
    "            weights=[embedding_matrix]\n",
    "        ),\n",
    "        tf.keras.layers.Conv1D(\n",
    "            hp.Int('conv1d', min_value=32, max_value=512, step=32),\n",
    "            kernel_size=3,\n",
    "            activation=hp.Choice('activation1', ['relu', 'sigmoid'])\n",
    "        ),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        tf.keras.layers.LSTM(\n",
    "            hp.Int('lstm1', min_value=32, max_value=512, step=32),\n",
    "            dropout=hp.Choice('dropout1', [.0, .2, .4, .6]),\n",
    "            return_sequences=True\n",
    "        ),\n",
    "        tf.keras.layers.LSTM(\n",
    "            hp.Int('lstm2', min_value=32, max_value=512, step=32),\n",
    "            dropout=hp.Choice('dropout2', [.0, .2, .4, .6])\n",
    "        ),\n",
    "        tf.keras.layers.Dense(\n",
    "            hp.Int('dense1', min_value=32, max_value=512, step=32),\n",
    "            activation=hp.Choice('activation2', ['relu', 'sigmoid'])\n",
    "        ),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  optimizer=tf.keras.optimizers.Adam(hp.Choice('opt',[1e-2,1e-3,1e-4])),\n",
    "                  metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "        build_model,\n",
    "        objective='val_loss',\n",
    "        max_trials=10,\n",
    "        overwrite=True,\n",
    "        directory=address,\n",
    "        project_name=\"sentiment_model\")\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks = [early_stopping, modelCheckpoint],\n",
    "                    verbose=2)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "The optimal parameters are:\n",
    "Conv1D layer: {best_hps.get('conv1d')}\n",
    "Activation function 1: {best_hps.get('activation1')}\n",
    "LSTM layer 1: {best_hps.get('lstm1')}\n",
    "Dropout rate 1: {best_hps.get('dropout1')}\n",
    "LSTM layer 2: {best_hps.get('lstm2')}\n",
    "Dropout rate 2: {best_hps.get('dropout2')}\n",
    "Dense layer 1: {best_hps.get('dense1')}\n",
    "Activation function 2: {best_hps.get('activation2')}\n",
    "Learning rate for the optimizer: {best_hps.get('opt')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4f33f7",
   "metadata": {},
   "source": [
    "### Model Summary\n",
    "The model summary provides an overview of the architecture of the CNN-LSTM model and the number of parameters in each layer. The summary also includes the results of hyperparameter tuning, highlighting the best validation loss achieved and the optimal hyperparameters.\n",
    "\n",
    "The CNN-LSTM model consists of the following layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef847ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546561df",
   "metadata": {},
   "source": [
    "The model summary shows the output shape of each layer, indicating the dimensions of the data at each stage of the model's architecture. It also provides the number of parameters associated with each layer.\n",
    "\n",
    "In total, the model has 1,929,241 parameters. Out of these, 608,641 parameters are trainable, meaning they will be updated during model training based on the optimization algorithm. The remaining 1,320,600 parameters are non-trainable, representing the pre-trained word embeddings used in the embedding layer.\n",
    "\n",
    "The hyperparameter tuning process resulted in a best validation loss of 0.4289. The optimal hyperparameters identified are as follows:\n",
    "\n",
    "- Conv1D layer: 128 filters\n",
    "- Activation function 1: ReLU\n",
    "- LSTM layer: 256 units\n",
    "- Dropout rate: 0.6\n",
    "- Dense layer 1: 384 units\n",
    "- Activation function 2: Sigmoid\n",
    "- Learning rate for the optimizer: 0.01\n",
    "\n",
    "These optimal hyperparameters were chosen to maximize the model's performance in sentiment analysis.\n",
    "\n",
    "By examining the model summary and understanding the impact of the hyperparameters, we can gain insights into the architecture and configuration of the CNN-LSTM model, facilitating further analysis and interpretation of its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae48f6b",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "The model training phase involved training the CNN-LSTM model using the optimal hyperparameters determined through hyperparameter tuning. The goal was to find the optimal epoch that yielded the highest validation accuracy and lowest validation loss.\n",
    "\n",
    "The model was trained on the training data for a maximum of 100 epochs. The training progress and model performance on the validation data were monitored throughout the training process. Two callbacks were used during training: early stopping and model checkpoint. Early stopping helped prevent overfitting by stopping the training process if the validation loss did not improve for a certain number of epochs. Model checkpoint saved the best model weights based on the validation loss.\n",
    "\n",
    "The training results were as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a964d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build model with optimal hyperparams and train it on the data\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks = [early_stopping, modelCheckpoint],\n",
    "                    verbose=2)\n",
    "\n",
    "val_loss_per_epoch = history.history['val_loss']\n",
    "best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b63c40b",
   "metadata": {},
   "source": [
    "The best epoch, determined based on the lowest validation loss, was epoch 12. At this epoch, the model achieved a validation loss of 0.4128 and a validation accuracy of 0.8223.\n",
    "\n",
    "By training the model with the optimal hyperparameters and selecting the best epoch, the aim was to maximize the model's performance in sentiment analysis and ensure its ability to generalize well to unseen data.\n",
    "\n",
    "The model training phase played a crucial role in fine-tuning the CNN-LSTM model and enabling it to learn patterns and relationships within the data, ultimately leading to improved accuracy and effectiveness in sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0a019a",
   "metadata": {},
   "source": [
    "### Retrain Model with Best Epoch\n",
    "After identifying the best epoch, the model was retrained using this optimal epoch to further enhance its performance. The retraining process involved using the hyperparameters obtained from the hyperparameter tuning and training the model on the training data for the determined best epoch.\n",
    "\n",
    "During the retraining process, the model's performance on both the training and validation data was monitored. The retrained model achieved improved results, demonstrating reduced loss and increased accuracy on the validation data compared to the initial training.\n",
    "\n",
    "Retraining the model with the best epoch allowed the model to further fine-tune its parameters and adjust its weights based on the training data. By leveraging the optimal epoch, the model was able to optimize its performance and improve its ability to classify sentiment accurately.\n",
    "\n",
    "The retraining process plays a vital role in enhancing the model's performance and ensuring its capability to make accurate predictions on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce41b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "history = hypermodel.fit(X_train, y_train, epochs=best_epoch,\n",
    "                validation_data=(X_test, y_test),\n",
    "                callbacks = [early_stopping, modelCheckpoint],\n",
    "                verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d11da42",
   "metadata": {},
   "source": [
    "### Evaluation of Model Performance\n",
    "To assess the performance of the model on the testing dataset, the loss and accuracy metrics were calculated. The loss value obtained was 0.4297, while the accuracy achieved was 81.72%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd9f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = hypermodel.evaluate(X_test, y_test)\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9928474e",
   "metadata": {},
   "source": [
    "These results provide insights into how well the model generalized to unseen data. The loss metric represents the discrepancy between the predicted and true labels, with a lower value indicating better performance. In this case, the obtained loss value of 0.4297 suggests that the model achieved a relatively low level of error in its predictions.\n",
    "\n",
    "The accuracy metric, on the other hand, reflects the proportion of correctly classified instances out of the total number of instances in the testing dataset. With an accuracy of 81.72%, the model demonstrated a reasonably high level of correctness in its predictions.\n",
    "\n",
    "These results highlight the effectiveness of the trained model in accurately classifying sentiment in unseen data. The combination of low loss and high accuracy indicates that the model has successfully captured meaningful patterns and relationships in the data, enabling it to make reliable predictions.\n",
    "\n",
    "By evaluating the model on the testing dataset, we can gain valuable insights into its real-world performance and validate its effectiveness in sentiment analysis tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aa68b0",
   "metadata": {},
   "source": [
    "### Visualization of Accuracy and Loss\n",
    "To gain further insights into the model's performance during training, two plots were generated: an accuracy plot and a loss plot. These plots provide a visual representation of the training and validation metrics across different epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20815d8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.ylim(None, 1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_graphs(history, 'loss')\n",
    "plt.ylim(0, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f708ad",
   "metadata": {},
   "source": [
    "In the code, a figure with a size of 16x8 inches is created. The `plot_graphs` function is then called to plot the accuracy and loss values. The accuracy plot is displayed in the left subplot, while the loss plot is shown in the right subplot.\n",
    "\n",
    "The accuracy plot illustrates the training and validation accuracy values over different epochs. It allows for the comparison of how well the model performs on both the training and validation datasets. The y-axis represents the accuracy values, ranging from 0 to 1, which indicates the proportion of correctly classified instances.\n",
    "\n",
    "The loss plot, on the other hand, showcases the training and validation loss values across epochs. It provides an understanding of how the model's loss decreases over time, indicating its ability to optimize the predictions. The y-axis represents the loss values, starting from 0 and increasing gradually.\n",
    "\n",
    "By examining these plots, one can identify the model's learning progress and evaluate its performance. It enables the assessment of whether the model is overfitting or underfitting, as well as understanding the optimal number of epochs for training.\n",
    "\n",
    "The accuracy and loss plots provide valuable insights into the model's training process and can aid in making informed decisions for further model optimization or adjustments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913a05f9",
   "metadata": {},
   "source": [
    "### CNN-LSTM Classification Report\n",
    "To evaluate the true performance of the CNN-LSTM model in sentiment analysis, we compare the predicted labels with the true labels on the test data. The F1-score, which combines precision and recall into a single metric, provides a reliable measure of the model's overall performance (Wood, 2019).\n",
    "\n",
    "The classification report below presents the F1-scores for each sentiment label:\n",
    "\n",
    "| Sentiment Label | F1-Score | Number of Samples |\n",
    "|-----------------|----------|------------------|\n",
    "| Negative (0)    | 80%      | 271              |\n",
    "| Positive (1)    | 81%      | 275              |\n",
    "\n",
    "The CNN-LSTM model achieved an F1-score of 80% for the negative sentiment label (label 0), indicating a reasonable balance between precision and recall. The model correctly identified negative sentiment in 80% of the samples belonging to this category. For the positive sentiment label (label 1), the model achieved an F1-score of 81%, demonstrating a similar balance between precision and recall in identifying positive sentiment.\n",
    "\n",
    "The classification report also provides precision, recall, and F1-score for each sentiment label. It reveals that the model achieved a precision of 83% and recall of 77% for the negative sentiment label, while for the positive sentiment label, the precision is 79% and recall is 84%. These metrics highlight the model's ability to make accurate predictions for both negative and positive sentiment.\n",
    "\n",
    "Overall, the CNN-LSTM model demonstrates a reasonable performance in sentiment analysis, achieving a balanced F1-score for both negative and positive sentiment labels. These results contribute to the comprehensive evaluation of the model's performance and provide valuable insights into its effectiveness in accurately classifying sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc2ffd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract predicted probabilities from neural network\n",
    "p_pred = model.predict(X_test)\n",
    "p_pred = p_pred.flatten()\n",
    "\n",
    "# Extract predicted class labels\n",
    "p = 0.5\n",
    "y_pred = p_pred > p\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bb3ca3",
   "metadata": {},
   "source": [
    "### CNN-LSTM Confusion Matrix Heatmap\n",
    "To visually analyze the performance of the CNN-LSTM model in sentiment analysis, a confusion matrix heatmap was generated using the `confusion_matrix` function from scikit-learn and visualized using the seaborn library. The confusion matrix provides valuable insights into the model's ability to predict sentiment accurately by presenting the counts of true positives, true negatives, false positives, and false negatives for each sentiment label.\n",
    "\n",
    "In the generated confusion matrix heatmap, the diagonal elements represent the true positives, indicating the number of correctly predicted samples for each sentiment class. For the negative sentiment (label 0), the model correctly classified 209 samples, demonstrating its accuracy in identifying negative sentiment. Similarly, for the positive sentiment (label 1), the model achieved 231 correct predictions, indicating its effectiveness in recognizing positive sentiment.\n",
    "\n",
    "The off-diagonal elements of the confusion matrix represent the false positives and false negatives. In this case, there were 44 false positives, where the model incorrectly predicted positive sentiment when the true sentiment was negative. Additionally, there were 62 false negatives, indicating instances where the model wrongly predicted negative sentiment when the true sentiment was positive.\n",
    "\n",
    "By examining the confusion matrix heatmap, we can gain a deeper understanding of the CNN-LSTM model's performance in terms of misclassifications and correct predictions for each sentiment label. This visualization enables a direct comparison between the logistic regression, random forest, and CNN-LSTM models, highlighting the strengths and weaknesses of each approach in sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494758d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "class_names=[\"0\", \"1\"]\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(nn_confusion_matrix), annot=True, cmap=\"viridis\" ,fmt='g', robust=True, center=0,\n",
    "           xticklabels=[\"0\", \"1\"], yticklabels=['0', '1'])\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('CNN-LSTM Confusion Matrix', y=1.1)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted');"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "3c43678b",
   "metadata": {},
   "source": [
    "### Summary and Implications\n",
    "The results of the data analysis show that the logistic regression model is better able to predict customer sentiment from the online customer reviews. The table below highlights the accuracy of both models:\n",
    "![image-2.png](attachment:image-2.png)\n",
    "The F1-scores indicate that the logistic regression has a macro average of 84% while the CNN-LSTM neural network was only able to achieve a macro average of 83%. Looking at the accuracy of the labels separately, both models were able to predict on label 1 for an F1-score of 93% but the neural network struggled with recall for label 0 and as such could only achieve an F1-score of 72%.\n",
    "\n",
    "One limitation of this analysis is that the classes were imbalanced and despite the application of class weights to the models, the classification reports clearly show that the effects of the imbalance were still present even though these results were improved above baseline models without weights applied.\n",
    "\n",
    "Based on these results, the clothing company should utilize the logistic regression model to monitor customer reviews as it can successfully analyze customer sentiment on new online reviews with 84% accuracy. This will allow the company to quickly identify potential issues such as the loss of consumer support and improve the products and services they offer to capitalize on these positive customer experiences (Kumar, 2021).\n",
    "\n",
    "Suggestions for future study are:\n",
    "•\tUse an ensemble classification method such as random forest to enhance accuracy and limit impact of class imbalance\n",
    "•\tUse a different variable for the sentiment labels such as Rating that might more accurately capture customer sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36320c89",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S., Davis, A., Dean, J., Devin, M., Ghemawat, S., Goodfellow, I., Harp, A., Irving, G., Isard, M., Jozefowicz, R., Jia, Y., Kaiser, L., Kudlur, M., … Zheng, X. (2015). TensorFlow: Large-scale machine learning on heterogeneous systems. TensorFlow. Retrieved from https://www.tensorflow.org/ \n",
    "\n",
    "Chakure, A. (2020, November 06). Random Forest and Its Implementation. Retrieved from https://medium.com/swlh/random-forest-and-its-implementation-71824ced454f\n",
    "\n",
    "Feature Engineering for NLP in Python. (n.d.). DataCamp. Retrieved January 18, 2022, from https://app.datacamp.com/learn/courses/feature-engineering-for-nlp-in-python\n",
    "\n",
    "Google. (n.d.). Classification: Precision and recall | machine learning crash course | google developers. Google. Retrieved May 17, 2022, from https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall\n",
    "\n",
    "Introduction to Deep Learning with Keras. (n.d.). DataCamp. Retrieved February 20, 2022, from https://app.datacamp.com/learn/courses/introduction-to-deep-learning-with-keras\n",
    "\n",
    "K, G. M. (2020, July 18). Machine Learning Basics: Random Forest Regression. Retrieved from https://towardsdatascience.com/machine-learning-basics-random-forest-regression-be3e1e3bb91a\n",
    "\n",
    "Kotzias, D., Denil, M., De Freitas, N., & Smyth, P. (2015). From Group to Individual Labels using Deep Features. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.\n",
    "\n",
    "Kumar, S. (2021, July 14). Top 5 business use cases of sentiment analysis. An Indium Software Company. Retrieved March 2, 2022, from https://www.tex-ai.com/top-5-use-cases-of-sentiment-analysis/\n",
    "\n",
    "Leung, K. (2022, January 9). Micro, Macro & weighted averages of F1 score, clearly explained. Medium. Retrieved May 17, 2022, from https://towardsdatascience.com/micro-macro-weighted-averages-of-f1-score-clearly-explained-b603420b292f\n",
    "Machine Learning with Tree-Based Models in Python. (n.d.). Retrieved from https://learn.datacamp.com/courses/machine-learning-with-tree-based-models-in-python\n",
    "\n",
    "Machine Learning with Tree-Based Models in Python. (n.d.). Retrieved from https://learn.datacamp.com/courses/machine-learning-with-tree-based-models-in-python\n",
    "\n",
    "Pedregosa et al. (2011). Scikit-learn: Machine learning in Python. Journal of Machine Learning Research. Retrieved May 17, 2022, from https://jmlr.org/papers/volume12/pedregosa11a/pedregosa11a.pdf\n",
    "\n",
    "Pierson, L. (2019, October 24). Retrieved from https://www.linkedin.com/learning/python-for-data-science-essential-training-part-1/\n",
    "\n",
    "Pierson, L. (2019, October 25). Retrieved from https://www.linkedin.com/learning/python-for-data-science-essential-training-part-2/\n",
    "\n",
    "Prosise, J. (2021, October 4). Text classification with Neural Networks. Atmosera. Retrieved February 20, 2022, from https://www.atmosera.com/blog/text-classification-with-neural-networks/\n",
    "\n",
    "Python Logistic Regression with Sklearn & Scikit. (n.d.). Retrieved from https://www.datacamp.com/community/tutorials/understanding-logistic-regression-python\n",
    "\n",
    "Text classification with an RNN:  Tensorflow. TensorFlow. (n.d.). Retrieved February 20, 2022, from https://www.tensorflow.org/text/tutorials/text_classification_rnn \n",
    "\n",
    "Wood, T. (2019, May 17). F-score. DeepAI. Retrieved May 17, 2022, from https://deepai.org/machine-learning-glossary-and-terms/f-score\n",
    "\n",
    "Wong, A. (2020, April 05). Random Forest Deep Dive & Beyond - ML for coders by Fast.ai (Lesson 2). Retrieved from https://medium.com/analytics-vidhya/random-forest-deep-dive-beyond-ml-for-coders-by-fast-ai-lesson-2-72c509900bab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
